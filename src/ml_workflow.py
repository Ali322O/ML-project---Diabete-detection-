# Description :
#     Ce fichier contient toutes les fonctions du pipeline :
#     - Nettoyage des donn√©es
#     - Gestion des valeurs manquantes
#     - Normalisation
#     - Split train/test
#     - Entra√Ænement de plusieurs mod√®les
#     - S√©lection de variables
#     - √âvaluation des performances



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler 
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score


# 1. Chargement des donn√©es

def load_data(filepath: str) -> pd.DataFrame:
    
    """
    Charge le dataset en fonction de son type (CSV ou .data) et retourne un DataFrame pandas

    On g√®re ici deux cas :
    - Dataset de type CSV ( Diabetes)
    - Dataset Spambase (.data sans header, avec .names s√©par√©)

    Args:
        filepath (str)
    Returns:
        pd.DataFrame
    """

    

    # Cas du fichier CSV Diabetes
    
    if filepath.endswith(".csv"):
        df = pd.read_csv(filepath)
        print(f"Dataset CSV charg√© : {df.shape[0]} lignes, {df.shape[1]} colonnes")

    # Cas du fichier .data Spambase
    
    elif filepath.endswith(".data"):
        
        # On reconstruit le chemin du fichier .names correspondant
        names_path = filepath.replace(".data", ".names")

        # Lecture des noms de colonnes depuis le .names
        with open(names_path, "r") as f:
            lines = f.readlines()

        # Les noms de colonnes se trouvent apr√®s une ligne vide dans .names
        col_names = []
        for line in lines:
            if ":" in line and not line.startswith("|"):
                col_names.append(line.split(":")[0].strip())

        # On ajoute la colonne cible "spam"
        col_names.append("spam")

        # Lecture du fichier principal avec les bons noms de colonnes
        df = pd.read_csv(filepath, header=None, names=col_names)
        print(f"Dataset Spambase charg√© : {df.shape[0]} lignes, {df.shape[1]} colonnes")

    else:
        raise ValueError(" Format de fichier non reconnu ")

    print(" apercu des donn√©es :")
    print(df.head())
    return df

# 2. Pr√©traitement des donn√©es

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Pr√©traite les donn√©es :
    - G√®re les valeurs manquantes
    - Normalise toutes les colonnes num√©riques (hors variable cible)
    - Encode les variables cat√©gorielles si besoin (ici, aucune)
    
    Args:
        df (pd.DataFrame)
    Returns:
        pd.DataFrame
    """

    df_clean = df.copy()

    # Gestion des valeurs manquantes
    
    missing_count = df_clean.isnull().sum().sum()
    if missing_count > 0:
        print(f"{missing_count} valeurs manquantes d√©tect√©es ‚Üí imputation moyenne.")
        df_clean = df_clean.fillna(df_clean.mean(numeric_only=True))
    else:
        print("Aucune valeur manquante d√©tect√©e.")

    # D√©tection de la colonne cible
    target_col = None
    for possible_target in ["spam", "Diabetes_binary", "Outcome", "class"]:
        if possible_target in df_clean.columns:
            target_col = possible_target
            break

    if target_col is None:
        raise ValueError(" Impossible d‚Äôidentifier la colonne cible dans le dataset")

    print(f" Colonne cible d√©tect√©e : '{target_col}'")

    # Normalisation des variables num√©riques
    features = df_clean.drop(columns=[target_col])
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)

    # Reconstituer le DataFrame normalis√©
    df_scaled = pd.DataFrame(features_scaled, columns=features.columns)
    df_scaled[target_col] = df_clean[target_col].values
    print(f"Normalisation termin√©e : {df_scaled.shape[1]} variables normalis√©es.")
    return df_scaled


# 3. S√©paration train/test

def split_data(df: pd.DataFrame, target_column: str = None, test_size: float = 0.2, random_state: int = 42):
    """
    S√©pare le dataset en ensembles d'entra√Ænement et de test.

    Args:
        df (pd.DataFrame): le dataframe pr√©trait√© par la fct preprocess_data
        target_column (str, optional): nom de la variable cible. Si None, essaye de la d√©tecter automatiquement
        test_size (float): proportion du jeu de test (ex: 0.2 = 20%)
        random_state (int): graine al√©atoire pour la reproductibilit√©

    Returns:
        tuple: X_train, X_test, y_train, y_test
    """

    df_copy = df.copy()

    # Identifier la colonne cible si non pr√©cis√©e
    if target_column is None:
        for possible_target in ["spam", "Diabetes_binary", "Outcome", "class"]:
            if possible_target in df_copy.columns:
                target_column = possible_target
                break

    if target_column is None:
        raise ValueError(" Impossible d'identifier la colonne cible automatiquement.")

    print(f"Colonne cible utilis√©e : '{target_column}'")

    # S√©parer X et y
    X = df_copy.drop(columns=[target_column])
    y = df_copy[target_column]

    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y)

    print(f" Split effectu√© : {X_train.shape[0]} train / {X_test.shape[0]} test")
    return X_train, X_test, y_train, y_test




# 4. Entra√Ænement des mod√®les

def train_models(X_train, X_test, y_train, y_test):
    """
    Entra√Æne plusieurs mod√®les de classification et compare leurs performances
    Mod√®les utilis√©s ( √† changer si besoin , selon les performances qu on aura ) :
      - Random Forest
      - KNN
      - R√©seau de neurones "simple" (MLP)
    
    Args:
        X_train, X_test, y_train, y_test : ensembles d'entra√Ænement et de test

    Returns:
        dict: mod√®les entra√Æn√©s
        dict: scores de performance (accuracy et F1 score )
    """

    # On d√©finit les mod√®les √† tester
    models = {
        "RandomForest": RandomForestClassifier(random_state=42, n_estimators=800, n_jobs=-1, max_leaf_nodes=24 , weight = 'balanced'),
        "KNN": KNeighborsClassifier(n_neighbors=10 , random_state=42 , n_jobs=-1),
        "NeuralNet": MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42 ,  n_jobs=-1)
    }

    trained_models = {}
    results = {}

    # On entraine chaque mod√®le et on √©value ses performances
    for name, model in models.items():
        print(f"\n Entra√Ænement du mod√®le : {name}")
        model.fit(X_train, y_train)  
        y_pred = model.predict(X_test)  
        
        acc = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        trained_models[name] = model
        results[name] = {"accuracy": acc, "f1_score": f1}

        print(f" {name} entra√Æn√© ‚Äî Accuracy: {acc:.3f} | F1: {f1:.3f}")

    print("\n R√©sum√© des performances :")
    for name, scores in results.items():
        print(f"{name:<12} ‚Üí Accuracy: {scores['accuracy']:.3f} | F1: {scores['f1_score']:.3f}")

    return trained_models, results



# 5. √âvaluation des mod√®les

def evaluate_models(models, X_test, y_test):
    """
    √âvalue plusieurs mod√®les sur un jeu de test :
    - Affiche la matrice de confusion
    - Affiche le rapport de classification
    - R√©sume les scores globaux
    
    Args:
        models (dict): dictionnaire {nom: mod√®le_entra√Æn√©}
        X_test (DataFrame): features du test set
        y_test (Series): labels du test set
    
    Returns:
        dict: dictionnaire des rapports (texte + matrices)
    """

    evaluations = {}

    for name, model in models.items():
        print(f"\nüîç √âvaluation du mod√®le : {name}")
        y_pred = model.predict(X_test)

        # Rapport de la classification et matrice de confusion
        report = classification_report(y_test, y_pred, output_dict=True)
        cm = confusion_matrix(y_test, y_pred)

        # Affichage r√©sum√©
        print("Matrice de confusion :")
        print(cm)
        print("\nRapport de classification :")
        print(classification_report(y_test, y_pred))

        # Stocker les r√©sultats
        evaluations[name] = {
            "classification_report": report,
            "confusion_matrix": cm
        }
    return evaluations


# 6. S√©lection de variables

def select_features(model, X_train, top_n=10):
    """
    S√©lectionne les variables les plus importantes selon un mod√®le de type RandomForest.

    Args:
        model: mod√®le entra√Æn√© (doit avoir un attribut 'feature_importances_')
        X_train (DataFrame): donn√©es d'entra√Ænement (features)
        top_n (int): nombre de variables les plus importantes √† afficher

    Returns:
        DataFrame: tableau des variables les plus importantes
    """

    # V√©rification que le mod√®le permet l'analyse des features
    if not hasattr(model, "feature_importances_"):
        raise AttributeError(" Le mod√®le choisi ne poss√®de pas 'feature_importances_' ")

    # Extraire les importances et les trier
    importances = model.feature_importances_
    feature_names = np.array(X_train.columns)
    sorted_idx = np.argsort(importances)[::-1] 

    top_features = pd.DataFrame({
        "Feature": feature_names[sorted_idx][:top_n],
        "Importance": importances[sorted_idx][:top_n]
    })

    print(f"\n Top {top_n} variables les plus importantes :")
    print(top_features.to_string(index=False))

    return top_features

# 7. Fonction principale ( pour suivre le pipeline complet)

def run_full_pipeline(filepath: str, target_column: str = None):
    """
    Ex√©cute l'ensemble du pipeline Machine Learning sur un dataset :
    - Chargement des donn√©es
    - Pr√©traitement
    - Split train/test
    - Entra√Ænement de plusieurs mod√®les
    - √âvaluation
    - S√©lection des features importantes (si applicable)

    Args:
        filepath (str): chemin vers le dataset
        target_column (str, optional): nom de la variable cible (sinon d√©tection automatique)

    Returns:
        None (affiche les r√©sultats)
    """

    df = load_data(filepath)

    
    df_clean = preprocess_data(df)

    X_train, X_test, y_train, y_test = split_data(df_clean, target_column=target_column)

    models, results = train_models(X_train, X_test, y_train, y_test)

    
    evaluate_models(models, X_test, y_test)

    # S√©lection des variables importantes (si applicable)
    
    if "RandomForest" in models:
        print("\n Analyse des variables importantes avec le mod√®le RandomForest :")
        select_features(models["RandomForest"], X_train, top_n=10)
    else:
        print(" Le mod√®le RandomForest n'a pas √©t√© entra√Æn√© : pas d'analyse des variables importantes possible ")
    
    


